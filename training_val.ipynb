{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_val.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNgp5Dvkcuy+DeA2WyvBf4B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmswl0707/Face-Expression-Recognition_with-DNN/blob/main/training_val.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGiD_mGB7jyV"
      },
      "source": [
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "\n",
        "# ckplus_res 데이터 다운받고 불러오기\n",
        "root = 'C:/Users/ChoiEunJi/Desktop/ckplus_res'\n",
        "\n",
        "#불러온 데이터 로드하기\n",
        "\n",
        "def load_data():\n",
        "    transforms = transforms.Compose([transforms.ToTensor(), transforms.Nomalize((),())])\n",
        "\n",
        "    train_dataset = torchvision.datasets.ckplus_res(root, train = True , download = True)\n",
        "    test_dataset = torchvision.datasets.ckplus_res(root, test = True, download = True)\n",
        "\n",
        "def split_train_val_test(train_dataset, test_dataset, p=0.8):\n",
        "    train_set_num = int(len(train_dataset.data)*p)\n",
        "    \n",
        "    train_data, val_data = torch.utils.data.random_split(train_dataset, [train_set_num, len(train_dataset)-train_set_num])\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=True)\n",
        "    test_loader=torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)\n",
        "    \n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "#로드 할때 train 데이터에 20%는 validation을 위해 나\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaLpxBJRl8rS"
      },
      "source": [
        "num_classes = 7\n",
        "\n",
        "num_of_samples = img_data.shape[0]\n",
        "labels = np.ones((num_of_samples,),dtype='int64')\n",
        "\n",
        "labels[0:29]=0 #30\n",
        "labels[30:59]=1 #29\n",
        "labels[60:92]=2 #32\n",
        "labels[93:124]=3 #31\n",
        "labels[125:155]=4 #30\n",
        "labels[156:187]=5 #31\n",
        "labels[188:]=6 #30\n",
        "\n",
        "names = ['ANGRY','DISGUST','FEAR','HAPPY','NEUTRAL','SAD','SURPRISE']\n",
        "\n",
        "def getLabel(id):\n",
        "    return ['ANGRY','DISGUST','FEAR','HAPPY','NEUTRAL','SAD','SURPRISE'][id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krqGNFzTmChI"
      },
      "source": [
        "# convert class labels to on-hot encoding# conve \n",
        "Y = np_utils.to_categorical(labels, num_classes)\n",
        "\n",
        "#Shuffle the dataset\n",
        "x,y = shuffle(img_data,Y, random_state=2)\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o60W_C9qk-uh"
      },
      "source": [
        "def conv_block_1(in_dim, out_dim, act_fn, stride=1):\n",
        "    model=nn.Sequential(\n",
        "        nn.Conv2d(in_dim,out_dim, kernerl_size=1, stride=stride),\n",
        "        act_fn, ##???\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def conv_block_3(in_dim, out_dim, act_fn):\n",
        "    model=nn.Sequential(\n",
        "        nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
        "        act_fn,\n",
        "    )\n",
        "    return model \n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "    def __init__(self, in_dim, mid_dim, out_dim, act_fn,down=False):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.act_fn=act_fn\n",
        "        self.down=down\n",
        "\n",
        "        if self.down:\n",
        "            self.layer=nn.Sequential(\n",
        "                conv_block_1(in_dim, mid_dim, act_fn,2),\n",
        "                conv_block_3(mid_dim, mid_dim, act_fn),\n",
        "                conv_block_1(mid_dim,out_dim, act_fn),\n",
        "            )\n",
        "            self.downsample=nn.Conv2d(in_dim, out_dim,1,2)\n",
        "        else:\n",
        "            self.layer=nn.Sequential(\n",
        "                conv_block_1(in_dim, mid_dim, act_fn),\n",
        "                conv_block_3(mid_dim, mid_dim, act_fn),\n",
        "                conv_block_1(mid_dim, out_dim, act_fn),\n",
        "            )\n",
        "            self.dim_equalizer=nn.Conv2d(in_dim, out_dim, kernel_size=1)\n",
        "\n",
        "        def forward(self, x):\n",
        "            if self.down:\n",
        "                dpwnsample=self.downsample(x)\n",
        "                out=self.layer(x)\n",
        "                out=out+downsample\n",
        "            else:\n",
        "                out=self.layer(x)\n",
        "                if x.size() is not out.size():\n",
        "                    x=self.dim_equalizer(x)\n",
        "                out=out+x\n",
        "            return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, base_dim, num_classes=2):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.act_fn=nn.ReLU()\n",
        "        self.layer_1=nn.Sequential(\n",
        "            nn.Conv2d(3, base_dim,7,2,3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3,2,1),\n",
        "        )\n",
        "        self.layer_2=nn.Sequential(\n",
        "            BottleNeck(base_dim, base_dim, base_dim*4, self.act_fn),\n",
        "            BottleNeck(base_dim*4, base_dim, base_dim*4, self.act_fn),\n",
        "            BottleNeck(base_dim*4, base_dim, base_dim*4, self.act_fn, down=True),\n",
        "        )\n",
        "        self.layer_3=nn.Sequential(\n",
        "            BottleNeck(base_dim*4, base_dim*2, base_dim*8, self.act_fn),\n",
        "            BottleNeck(base_dim*8, base_dim*2, base_dim*8, self.act_fn),\n",
        "            BottleNeck(base_dim*8, base_dim*2, base_dim*8, self.act_fn),\n",
        "            BottleNeck(base_dim*8, base_dim*2, base_dim*8, self.act_fn, down=True),\n",
        "        )\n",
        "        self.layer_4=nn.Sequential(\n",
        "            BottleNeck(base_dim*8, base_dim*4, base_dim*16, self.act_fn),\n",
        "            BottleNeck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
        "            BottleNeck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
        "            BottleNeck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
        "            BottleNeck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
        "            BottleNeck(base_dim*16, base_dim*4, base_dim*16, self.act_fn, down=True),\n",
        "        \n",
        "        self.layer_5=nn.Sequential(\n",
        "            BottleNeck(base_dim*16, base_dim*8, base_dim*32, self.act_fn),\n",
        "            BottleNeck(base_dim*32, base_dim*8, base_dim*32, self.act_fn),\n",
        "            BottleNeck(base_dim*32, base_dim*8, base_dim*32, self.act_fn),\n",
        "        )\n",
        "        self.avgpool= nn.AvgPool2d(7,1)\n",
        "        self.fc_layer=nn.Linear(base_dim*32, num_classes)\n",
        "\n",
        "        def forward(self,x):\n",
        "            out=self.layer_1(x)\n",
        "            out=self.layer_2(out)\n",
        "            out=self.layer_3(out)\n",
        "            out=self.layer_4(out)\n",
        "            out=self.layer_5(out)\n",
        "            out=self.avgpool(out)\n",
        "            out=out.view(batch_size, -1)\n",
        "            out=self.fc_layer(out)\n",
        "            return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAtjoX2vdNCz"
      },
      "source": [
        "#train 및 test하는 메소\n",
        "def train(epoch, model, train_loader, val_loader):\n",
        "    #model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    global_step = 0\n",
        "    for e in range(epoch):\n",
        "        for batch_idx, (input, target) in enumerate(train_loader):\n",
        "            global_step = e * len(train_loader) * batch_size + (batch_idx * batch_size)\n",
        "\n",
        "            input, target = input.cuda(), target.cuda()\n",
        "            input, target = Variable(input), Variable(target)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(input)\n",
        "            loss=F.nll_loss(output, target)\n",
        "            preds = output.data.max(dim=1, keepdim=True)[1]\n",
        "            acc=preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "            train_loss +=F.nll_loss(output, target, reduction='sum').data.item()\n",
        "            train_acc +=acc.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_acc, val_loss = test(model, val_loader)\n",
        "            writer.add_scalar('Loss/val', val_loss, global_step)\n",
        "            writer.add_scalar('Accuracy/val', val_acc, global_step)\n",
        "\n",
        "        loss = train_loss/len(train_loader.dataset)\n",
        "        accuracy = 100.0 * train_acc/len(train_loader.dataset)\n",
        "        writer.add_scalar('Loss/train', loss, global_step)\n",
        "        writer.add_scalar('Accuracy/train', accuracy, global_step)\n",
        "\n",
        "        print('Epoch: {0:4} iter: {1:10} loss {2:3.5f} acc {3:3.5f} \\t v_loss {4:3.5f} v_acc {5:3.5f}'\n",
        "              .format(e+1, global_step, loss, accuracy, val_loss, val_acc))\n",
        "        \n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbWbp9HPdFAy"
      },
      "source": [
        "def test(model, data_loader):\n",
        "    #model.eval()\n",
        "\n",
        "    running_acc = 0.0\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (input, target) in enumerate(data_loader):\n",
        "\n",
        "        input, target = input.cuda(), target.cuda()\n",
        "        input, target = Variable(input), Variable(target)\n",
        "\n",
        "        output = model(input)\n",
        "\n",
        "        preds = output.data.max(dim=1, keepdim=True)[1]\n",
        "        acc = preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "        running_loss +=F.nll_loss(output, target, reduction='sum').data.item()\n",
        "        running_acc += acc.item()\n",
        "\n",
        "    accuracy = 100.0 * running_acc / len(data_loader.dataset)\n",
        "    loss = running_loss / len(data_loader.dataset)\n",
        "\n",
        "    return accuracy, loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFVyCBjVeUz-"
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "    writer = SummaryWriter()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    #hyperparameter\n",
        "    lr = 0.003\n",
        "    epoch = 50\n",
        "    batch_size = 512\n",
        "    train_val_p=0.8\n",
        "\n",
        "    #데이터 셋 로드 및 train, val, test로 데이터 셋 나눔\n",
        "    train_dataset, test_dataset = load_mnist()\n",
        "    train_loader, val_loader, test_loader = split_train_val_test(train_dataset, test_dataset, p=train_val_p)\n",
        "\n",
        "    #모델 불러오고, optimizer 설정\n",
        "    model = Net().to(device)                            # 모델 불러오기\n",
        "    optimizer = optim.SGD(model.parameters(), lr)      #optimizer 설정\n",
        "\n",
        "    #layer 정보 프린트 하기\n",
        "    print(summary(model, input_size=(1, 28, 28)))\n",
        "\n",
        "    train(epoch, model, train_loader, val_loader)   #학습\n",
        "    acc, _ = test(model, test_loader)               #테스트\n",
        "\n",
        "    print('test acc {0:3.5f}' .format(acc))\n",
        "    writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}