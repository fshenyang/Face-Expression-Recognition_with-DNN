{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_val.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOtdi6VPjsYtmbepNUvmSuR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmswl0707/Face-Expression-Recognition_with-DNN/blob/main/training_val.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGiD_mGB7jyV"
      },
      "source": [
        "\n",
        "\n",
        "# mnist 데이터 다운받고 불러오기\n",
        "def load_mnist():\n",
        "    transformation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])\n",
        "\n",
        "    train_dataset=datasets.MNIST('data/', train=True, transform=transformation, download=True)\n",
        "    test_dataset=datasets.MNIST('data/', train=False, transform=transformation, download=True)\n",
        "\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "#불러온 데이터 로드하기\n",
        "#로드 할때 train 데이터에 20%는 validation을 위해 나\n",
        "def split_train_val_test(train_dataset, test_dataset, p=0.8):\n",
        "    train_set_num = int(len(train_dataset.data)*p)\n",
        "\n",
        "    train_data, val_data = torch.utils.data.random_split(train_dataset, [train_set_num, len(train_dataset)-train_set_num])\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=True)\n",
        "    test_loader=torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "#train 및 test하는 메소\n",
        "def train(epoch, model, train_loader, val_loader):\n",
        "    #model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    global_step = 0\n",
        "    for e in range(epoch):\n",
        "        for batch_idx, (input, target) in enumerate(train_loader):\n",
        "            global_step = e * len(train_loader) * batch_size + (batch_idx * batch_size)\n",
        "\n",
        "            input, target = input.cuda(), target.cuda()\n",
        "            input, target = Variable(input), Variable(target)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(input)\n",
        "            loss=F.nll_loss(output, target)\n",
        "            preds = output.data.max(dim=1, keepdim=True)[1]\n",
        "            acc=preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "            train_loss +=F.nll_loss(output, target, reduction='sum').data.item()\n",
        "            train_acc +=acc.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_acc, val_loss = test(model, val_loader)\n",
        "            writer.add_scalar('Loss/val', val_loss, global_step)\n",
        "            writer.add_scalar('Accuracy/val', val_acc, global_step)\n",
        "\n",
        "        loss = train_loss/len(train_loader.dataset)\n",
        "        accuracy = 100.0 * train_acc/len(train_loader.dataset)\n",
        "        writer.add_scalar('Loss/train', loss, global_step)\n",
        "        writer.add_scalar('Accuracy/train', accuracy, global_step)\n",
        "\n",
        "        print('Epoch: {0:4} iter: {1:10} loss {2:3.5f} acc {3:3.5f} \\t v_loss {4:3.5f} v_acc {5:3.5f}'\n",
        "              .format(e+1, global_step, loss, accuracy, val_loss, val_acc))\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "\n",
        "\n",
        "def test(model, data_loader):\n",
        "    #model.eval()\n",
        "\n",
        "    running_acc = 0.0\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (input, target) in enumerate(data_loader):\n",
        "\n",
        "        input, target = input.cuda(), target.cuda()\n",
        "        input, target = Variable(input), Variable(target)\n",
        "\n",
        "        output = model(input)\n",
        "\n",
        "        preds = output.data.max(dim=1, keepdim=True)[1]\n",
        "        acc = preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "        running_loss +=F.nll_loss(output, target, reduction='sum').data.item()\n",
        "        running_acc += acc.item()\n",
        "\n",
        "    accuracy = 100.0 * running_acc / len(data_loader.dataset)\n",
        "    loss = running_loss / len(data_loader.dataset)\n",
        "\n",
        "    return accuracy, loss\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    writer = SummaryWriter()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    #hyperparameter\n",
        "    lr = 0.003\n",
        "    epoch = 50\n",
        "    batch_size = 512\n",
        "    train_val_p=0.8\n",
        "\n",
        "    #데이터 셋 로드 및 train, val, test로 데이터 셋 나눔\n",
        "    train_dataset, test_dataset = load_mnist()\n",
        "    train_loader, val_loader, test_loader = split_train_val_test(train_dataset, test_dataset, p=train_val_p)\n",
        "\n",
        "    #모델 불러오고, optimizer 설정\n",
        "    model = Net().to(device)                            # 모델 불러오기\n",
        "    optimizer = optim.SGD(model.parameters(), lr)      #optimizer 설정\n",
        "\n",
        "    #layer 정보 프린트 하기\n",
        "    print(summary(model, input_size=(1, 28, 28)))\n",
        "\n",
        "    train(epoch, model, train_loader, val_loader)   #학습\n",
        "    acc, _ = test(model, test_loader)               #테스트\n",
        "\n",
        "    print('test acc {0:3.5f}' .format(acc))\n",
        "    writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}